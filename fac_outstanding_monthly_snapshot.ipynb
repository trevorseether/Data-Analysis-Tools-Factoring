{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#### ACTUALIZAR MES EN EL fac_outstanding_monthly_snapshot\n","EL MES COLOCADO ES EL ÚNICO QUE SE ACTUALIZA, DEJA IGUAL TODOS LOS DEMÁS"],"metadata":{"id":"wfnYmsZD7otT"}},{"cell_type":"code","source":["#%% Corte mensual actual\n","mes_incorporar = '2025-09-30' # último día del mes, cambiar en cada ejecución"],"metadata":{"id":"riu2Xj5B9VTu","executionInfo":{"status":"ok","timestamp":1762789147989,"user_tz":300,"elapsed":28,"user":{"displayName":"Joseph Montoya","userId":"07745622955384668359"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["hoy_formateado = datetime.today().strftime('%Y-%m-%d')"],"metadata":{"id":"FcfGFYylaTU7","executionInfo":{"status":"ok","timestamp":1762789147994,"user_tz":300,"elapsed":3,"user":{"displayName":"Joseph Montoya","userId":"07745622955384668359"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from datetime import datetime\n","inicio = datetime.now()\n","print(\"Inicio:\", inicio.strftime(\"%Y-%m-%d %H:%M:%S\"))\n","\n","import pandas as pd\n","!pip install boto3\n","import boto3\n","import json\n","import io\n","import os\n","import numpy as np\n","!pip install pyathena\n","from pyathena import connect\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","hoy_formateado = datetime.today().strftime('%Y-%m-%d')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_fwaeZR402F4","outputId":"e74feaf1-6214-4a76-ad47-32f0359d3707","executionInfo":{"status":"ok","timestamp":1762789160613,"user_tz":300,"elapsed":12621,"user":{"displayName":"Joseph Montoya","userId":"07745622955384668359"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Inicio: 2025-11-10 15:39:07\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.12/dist-packages (1.40.69)\n","Requirement already satisfied: botocore<1.41.0,>=1.40.69 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.40.69)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.0.1)\n","Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from boto3) (0.14.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.69->boto3) (2.9.0.post0)\n","Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.69->boto3) (2.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.69->boto3) (1.17.0)\n","Requirement already satisfied: pyathena in /usr/local/lib/python3.12/dist-packages (3.21.0)\n","Requirement already satisfied: boto3>=1.26.4 in /usr/local/lib/python3.12/dist-packages (from pyathena) (1.40.69)\n","Requirement already satisfied: botocore>=1.29.4 in /usr/local/lib/python3.12/dist-packages (from pyathena) (1.40.69)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from pyathena) (2025.3.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from pyathena) (2.9.0.post0)\n","Requirement already satisfied: tenacity>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from pyathena) (8.5.0)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3>=1.26.4->pyathena) (1.0.1)\n","Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from boto3>=1.26.4->pyathena) (0.14.0)\n","Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore>=1.29.4->pyathena) (2.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->pyathena) (1.17.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["txt_credenciales_athena = r\"credenciales actualizado.txt\" # arrastrar json de credenciales\n","\n","path = '/content/drive/MyDrive/BUSINESS ANALYTICS/FACTORING/PROYECTOS/fac_outstanding backups'"],"metadata":{"id":"10Za2DzG3IKy","executionInfo":{"status":"ok","timestamp":1762789160621,"user_tz":300,"elapsed":3,"user":{"displayName":"Joseph Montoya","userId":"07745622955384668359"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#%% funciones de transformación de fechas\n","mes_incorporar = pd.Timestamp(mes_incorporar)\n","\n","def eomonth(fecha):\n","    \"\"\"\n","    Devuelve el último día del mes de la fecha dada.\n","    \"\"\"\n","    fecha = pd.Timestamp(fecha)\n","    return fecha + pd.offsets.MonthEnd(0)\n","\n","def prev_month_eomonth(fecha):\n","    \"\"\"\n","    Devuelve el último día del mes anterior a la fecha dada.\n","    \"\"\"\n","    fecha = pd.Timestamp(fecha)  # asegurar tipo Timestamp\n","    fech2 = (fecha - pd.offsets.MonthBegin(1)) - pd.offsets.Day(1)\n","    return pd.Timestamp(fech2)\n","\n","def convertir_codmes(fecha):\n","    fecha = pd.Timestamp(mes_incorporar)\n","    yyyymm = fecha.strftime(\"%Y%m\")\n","    return yyyymm\n","\n","eo_mes_actual   = eomonth(mes_incorporar)\n","eo_mes_anterior = prev_month_eomonth(mes_incorporar)\n","codmes          = convertir_codmes(mes_incorporar)\n","print(codmes)"],"metadata":{"id":"kQ4ZAHij3Jmf","executionInfo":{"status":"ok","timestamp":1762789160644,"user_tz":300,"elapsed":19,"user":{"displayName":"Joseph Montoya","userId":"07745622955384668359"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"82b06bd6-9738-4c65-8030-ace1f167e5c6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["202509\n"]}]},{"cell_type":"code","source":["#%%\n","# Crea la carpeta si no existe\n","os.chdir(path)\n","\n","folder_name = codmes\n","os.makedirs(folder_name, exist_ok=True)\n","\n","os.chdir(path + '/' + folder_name)"],"metadata":{"id":"Rj4NdY9K3Nyx","executionInfo":{"status":"ok","timestamp":1762789162685,"user_tz":300,"elapsed":2038,"user":{"displayName":"Joseph Montoya","userId":"07745622955384668359"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QTYeMUwk5dDa"},"outputs":[],"source":["#%% Credenciales de AmazonAthena\n","with open('/content/' + txt_credenciales_athena) as f:\n","    creds = json.load(f)\n","\n","conn = connect(\n","    aws_access_key_id     = creds[\"AccessKeyId\"],\n","    aws_secret_access_key = creds[\"SecretAccessKey\"],\n","    aws_session_token     = creds[\"SessionToken\"],\n","    s3_staging_dir        = creds[\"s3_staging_dir\"],\n","    region_name           = creds[\"region_name\"]\n","\n","    )\n","\n","#%% lectura del corte anterior\n","\n","query = ''' select * from prod_datalake_master.\"ba__fac_outstanding_monthly_snapshot\"  '''\n","\n","cursor = conn.cursor()\n","cursor.execute(query)\n","\n","# Obtener los resultados\n","resultados = cursor.fetchall()\n","\n","# Obtener los nombres de las columnas\n","column_names = [desc[0] for desc in cursor.description]\n","\n","# Convertir los resultados a un DataFrame de pandas\n","df_corte = pd.DataFrame(resultados, columns = column_names)\n","\n","df_corte.to_excel(f'extraido {hoy_formateado}.xlsx', index = False)\n","\n","del df_corte['_timestamp']\n","\n","print(df_corte.shape)"]},{"cell_type":"code","source":["#%% mes actual que vamos a incorporar\n","\n","query = ''' select * from prod_datalake_analytics.\"fac_outst_unidos_f_desembolso_jmontoya\"  '''\n","\n","cursor = conn.cursor()\n","cursor.execute(query)\n","\n","# Obtener los resultados\n","resultados = cursor.fetchall()\n","\n","# Obtener los nombres de las columnas\n","column_names = [desc[0] for desc in cursor.description]\n","\n","# Convertir los resultados a un DataFrame de pandas\n","df_view = pd.DataFrame(resultados, columns = column_names)\n","print(df_view.shape)\n","\n","df_view.to_excel(f'fac_outstanding_tiempo_real_{codmes} - {hoy_formateado}.xlsx',\n","                  index = False)\n","\n","df_view_completo = df_view.copy()"],"metadata":{"id":"BnFesPnBzTgE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#%% agregando el mes actual\n","df_corte['codmes'] = df_corte['codmes'].astype(int)\n","df_corte = df_corte[ df_corte['codmes'] < int(codmes) ] #fitrando el mes actual en caso de que quisieramos añadir datos nuevamente\n","\n","df_view['codmes'] = df_view['codmes'].astype(int)\n","df_view  = df_view[ df_view['codmes'] == int(codmes)]\n","\n","#ASEGURANDO EL ORDENAMIENTO, PUES EXISTEN DIFERENCIAS POR MAYÚSCULAS Y MINÚSCULAS\n","columnas = ['code', 'fecha_cierre', 'codmes', 'product_type', 'client_ruc', 'client_name', 'provider_ruc', 'provider_name', 'flag_newclient', 'flag_newprovider', 'transfer_date', 'ANTERIOR_TRANSFER', 'currency_request', 'currency_auctions', 'assigned_financing_rate', 'total_net_amount_pending_payment', 'e_payment_date_original', 'amount_financed', 'terms', 'amount_advance', 'advance_percentage', 'invoice_count', 'amount_of_invoices', 'assigned_name', 'assigned_last_name', 'company_id', 'user_third_party_id', 'client_id', 'provider_id', 'request_id', 'client_payment_id', 'payment_currency', 'payment_date', 'total_amount_paid', 'capital_paid', 'interest_paid', 'guarantee_paid', 'last_status', 'last_paid_date', 'facturas_vencimientos_iguales', 'fecha_confirmada_hubspot', 'max_payment_date_invoices', 'e_payment_date', 'cambio_fecha_vencimiento', 'q_desembolso', 'm_desembolso', 'new_clients', 'recurrent_clients', 'new_providers', 'recurrent_providers', 'remaining_capital', 'remaining_total_amount', 'actual_status', 'flag_excluir', 'dias_atraso', 'm_desembolso_soles', 'remaining_capital_soles', 'amount_financed_soles', 'exchange_rate', 'codmes_transfer', 'PAR1_m', 'PAR15_m', 'PAR30_m', 'PAR60_m', 'PAR90_m', 'PAR120_m', 'PAR180_m', 'PAR360_m', 'PAR1_q', 'PAR15_q', 'PAR30_q', 'PAR60_q', 'PAR90_q', 'PAR120_q', 'PAR180_q', 'PAR360_q', 'q_vigente', 'condoned', 'judicialized', 'rango_dias_atraso', 'rango_duracion', 'PAR1_ms', 'PAR15_ms', 'PAR30_ms', 'PAR60_ms', 'PAR90_ms', 'PAR120_ms', 'PAR180_ms', 'PAR360_ms', 'FLAG_ORIGEN_OPERACION']\n","columnas_mayusc = [col.upper() for col in columnas]\n","cc = df_corte.columns\n","cc = [col.upper() for col in cc]\n","cv = df_view.columns\n","cv = [col.upper() for col in cv]\n","\n","df_corte.columns = cc\n","df_corte = df_corte[columnas_mayusc]\n","\n","df_view.columns = cv\n","df_view = df_view[columnas_mayusc]\n","\n","df_corte.columns = columnas\n","df_view.columns  = columnas\n","\n","df_concatenado = pd.concat([df_corte, df_view], ignore_index=True)\n","print(df_concatenado.shape)\n"],"metadata":{"id":"DidJkeAO7bAT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# bloque de código temporal para no incluir mes actual\n","df_concatenado = df_concatenado[df_concatenado['codmes'] != int(codmes)]\n","\n","print(df_concatenado['codmes'].unique())"],"metadata":{"id":"Cy9WKrkUhGkX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#%% CONVERTIR COLUMNAS DE FECHAS A UN SOLO FORMATO\n","n_alertas = 0\n","df_concatenado[\"fecha_cierre\"] = pd.to_datetime(df_concatenado[\"fecha_cierre\"],  format=\"mixed\")\n","df_concatenado[\"fecha_cierre\"] = df_concatenado[\"fecha_cierre\"].dt.strftime(\"%Y-%m-%d\")\n","alert = df_concatenado[ df_concatenado[\"fecha_cierre\"].isna() ]\n","if alert.shape[0]>0:\n","    print('alerta de nulos en fecha_cierre')\n","    n_alertas += 1\n","\n","df_concatenado[\"transfer_date\"] = pd.to_datetime(df_concatenado[\"transfer_date\"],  format=\"mixed\")\n","df_concatenado[\"transfer_date\"] = df_concatenado[\"transfer_date\"].dt.strftime(\"%Y-%m-%d\")\n","alert = df_concatenado[ df_concatenado[\"transfer_date\"].isna() ]\n","if alert.shape[0]>0:\n","    print('alerta de nulos en transfer_date')\n","    n_alertas += 1\n","\n","df_concatenado[\"e_payment_date_original\"] = pd.to_datetime(df_concatenado[\"e_payment_date_original\"],  format=\"mixed\")\n","df_concatenado[\"e_payment_date_original\"] = df_concatenado[\"e_payment_date_original\"].dt.strftime(\"%Y-%m-%d\")\n","alert = df_concatenado[ df_concatenado[\"e_payment_date_original\"].isna() ]\n","if alert.shape[0]>0:\n","    print('alerta de nulos en e_payment_date_original')\n","    n_alertas += 1\n","\n","df_concatenado[\"payment_date\"] = pd.to_datetime(df_concatenado[\"payment_date\"],  format=\"mixed\")\n","df_concatenado[\"payment_date\"] = df_concatenado[\"payment_date\"].dt.strftime(\"%Y-%m-%d\")\n","# alert = df_concatenado[ df_concatenado[\"payment_date\"].isna() ]\n","\n","df_concatenado[\"e_payment_date\"] = pd.to_datetime(df_concatenado[\"e_payment_date\"],  format=\"mixed\")\n","df_concatenado[\"e_payment_date\"] = df_concatenado[\"e_payment_date\"].dt.strftime(\"%Y-%m-%d\")\n","alert = df_concatenado[ df_concatenado[\"e_payment_date\"].isna() ]\n","if alert.shape[0]>0:\n","    print('alerta de nulos en e_payment_date')\n","    n_alertas += 1\n","\n","################################################################################\n","class StopExecution(Exception):\n","    pass\n","if n_alertas >= 1:\n","    raise StopExecution(\"Se canceló la ejecución por presencia de alertas\")\n","else:\n","    print(\"No se encontraron alertas\")\n","################################################################################\n"],"metadata":{"id":"y3XfMpCf7tg9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#%% obtener ruc del corte más reciente, para unirlo por codigo de subasta, a aquellos casos donde falte ruc\n","rucs = df_view_completo[['code', 'client_ruc', 'codmes']]\n","rucs = rucs.sort_values(by = 'codmes', ascending = False)\n","rucs = rucs.drop_duplicates(subset=['code'], keep=\"first\")\n","rucs = rucs[ ~pd.isna(rucs['client_ruc']) ]\n","del rucs['codmes']\n","rucs.columns = ['code_aux', 'ruc_aux']\n","\n","df_concatenado = df_concatenado.merge(rucs,\n","                                      left_on  = 'code',\n","                                      right_on = 'code_aux',\n","                                      how      = 'left')\n","df_concatenado['client_ruc'] = np.where( ~df_concatenado['ruc_aux'].isnull(),\n","                                         df_concatenado['ruc_aux'],\n","                                         df_concatenado['client_ruc'] )\n","del df_concatenado['code_aux']\n","del df_concatenado['ruc_aux']"],"metadata":{"id":"eErJ57BK783I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#%% limpieza de texto del client_ruc y provider_ruc\n","col_ruc = 'client_ruc'\n","df_concatenado[col_ruc] = (\n","    df_concatenado[col_ruc]\n","    .astype(str)                 # convierte todo a string\n","    .str.replace('.0','', regex=False)  # limpia floats mal guardados\n","    .replace('None', pd.NA)      # convierte 'None' a valor nulo real\n",")\n","vr = df_concatenado[ (df_concatenado[col_ruc] == 'None') | (pd.isna(df_concatenado[col_ruc]))]\n","\n","col_ruc = 'provider_ruc'\n","df_concatenado[col_ruc] = (\n","    df_concatenado[col_ruc]\n","    .astype(str)                 # convierte todo a string\n","    .str.replace('.0','', regex=False)  # limpia floats mal guardados\n","    .replace('None', pd.NA)      # convierte 'None' a valor nulo real\n",")\n","vr = df_concatenado[ (df_concatenado[col_ruc] == 'None') | (pd.isna(df_concatenado[col_ruc]))]"],"metadata":{"id":"P3pUa53T9FTu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#%% parchamiento del nombre del client_ruc\n","clientes = df_concatenado[['client_ruc', 'client_name', 'codmes']]\n","clientes = clientes.sort_values(by='codmes', ascending=False)\n","clientes = clientes.drop_duplicates(subset=['client_ruc'], keep=\"first\")\n","clientes = clientes[ ~pd.isna(clientes['client_ruc'])]\n","clientes = clientes[ ~pd.isna(clientes['client_name'])]\n","clientes.columns = ['client_ruc_aux', 'client_name_aux', 'codmes']\n","\n","df_concatenado = df_concatenado.merge(clientes[['client_ruc_aux', 'client_name_aux']],\n","                                  left_on  = 'client_ruc',\n","                                  right_on = 'client_ruc_aux',\n","                                  how      = 'left')\n","df_concatenado['client_name'] = np.where( ~df_concatenado['client_name_aux'].isnull(),\n","                                         df_concatenado['client_name_aux'],\n","                                         df_concatenado['client_name'])\n","del df_concatenado['client_ruc_aux']\n","del df_concatenado['client_name_aux']\n"],"metadata":{"id":"Iq0ce1te9IlR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#%% Colocando el client y provider actual, de manera retroactiva, y modificando la enumeración de nuevo o recurrente\n","\n","# df_concatenado = df_concatenado.sort_values(by = 'codmes', ascending = False) # este método solo actualiza a las ops que aparecen en el mes actual\n","# op_actual = df_concatenado[ df_concatenado['codmes'] == int(codmes) ]\n","df_view_completo = df_view_completo.sort_values(by = 'codmes', ascending = False)\n","op_actual = df_view_completo.drop_duplicates(subset=['code'], keep=\"first\")\n","\n","op_actual = op_actual[['code', 'client_ruc','client_name', 'provider_ruc', 'provider_name']]\n","op_actual.columns = ['code', 'client_ruc_aux','client_name_aux', 'provider_ruc_aux', 'provider_name_aux']\n","\n","df_concatenado = df_concatenado.merge(op_actual,\n","                                      on = 'code',\n","                                      how = 'left')\n","df_concatenado['client_ruc'] = np.where( df_concatenado['client_ruc_aux'].notna(),\n","                                         df_concatenado['client_ruc_aux'],\n","                                         df_concatenado['client_ruc'])\n","df_concatenado['client_name'] = np.where( df_concatenado['client_name_aux'].notna(),\n","                                          df_concatenado['client_name_aux'],\n","                                          df_concatenado['client_name'])\n","df_concatenado['provider_ruc'] = np.where( df_concatenado['provider_ruc_aux'].notna(),\n","                                           df_concatenado['provider_ruc_aux'],\n","                                           df_concatenado['provider_ruc'])\n","df_concatenado['provider_name'] = np.where( df_concatenado['provider_name_aux'].notna(),\n","                                            df_concatenado['provider_name_aux'],\n","                                            df_concatenado['provider_name'])\n","del df_concatenado['client_ruc_aux']\n","del df_concatenado['client_name_aux']\n","del df_concatenado['provider_ruc_aux']\n","del df_concatenado['provider_name_aux']"],"metadata":{"id":"ludzSxSGRHwk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#%% Corrección de flag_newclient flag_newprovider, new_clients, recurrent_clients, new_providers, recurrent_providers\n","df_concatenado['transfer_date_aux'] = pd.to_datetime(df_concatenado['transfer_date'])\n","df_concatenado = df_concatenado.sort_values(by = ['codmes', 'transfer_date_aux'], ascending = [True,True])\n","\n","# Creamos el contador acumulado para cada cliente\n","df_concatenado['flag_newclient'] = df_concatenado.groupby('client_ruc').cumcount() + 1\n","df_concatenado['flag_newclient'] = df_concatenado['flag_newclient'].fillna(0).astype(int)\n","df_concatenado['flag_newprovider'] = df_concatenado.groupby('provider_ruc').cumcount() + 1\n","df_concatenado['flag_newprovider'] = df_concatenado['flag_newprovider'].fillna(0).astype(int)\n","\n","df_concatenado['new_clients'] = np.where(df_concatenado['flag_newclient'] == 1,\n","                                         1,\n","                                         0).astype(int)\n","df_concatenado['recurrent_clients'] = np.where(df_concatenado['flag_newclient'] == 1,\n","                                         0,\n","                                         1).astype(int)\n","df_concatenado['new_providers'] = np.where(df_concatenado['flag_newprovider'] == 1,\n","                                         1,\n","                                         0).astype(int)\n","df_concatenado['recurrent_providers'] = np.where(df_concatenado['flag_newprovider'] == 1,\n","                                         0,\n","                                         1).astype(int)\n","\n","del df_concatenado['transfer_date_aux']\n","\n"],"metadata":{"id":"ITKeQ8F3bybg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#%%\n","\n","# Cliente de S3\n","s3 = boto3.client(\n","    \"s3\",\n","    aws_access_key_id       = creds[\"AccessKeyId\"],\n","    aws_secret_access_key   = creds[\"SecretAccessKey\"],\n","    aws_session_token       = creds[\"SessionToken\"],\n","    region_name             = creds[\"region_name\"]\n",")\n","\n","# ==== CONFIGURACIÓN ====\n","bucket_name = \"prod-datalake-raw-730335218320\"\n","s3_prefix = \"manual/ba/fac_outstanding_monthly_snapshot/\" # carpeta lógica en el bucket\n","\n","# ==== EXPORTAR A PARQUET EN MEMORIA ====\n","csv_buffer = io.StringIO()\n","df_concatenado.to_csv(csv_buffer, index=False, encoding=\"utf-8-sig\")\n","\n","# Nombre de archivo con timestamp (opcional, para histórico)\n","s3_key = f\"{s3_prefix}fac_outstanding_monthly_snapshot.csv\"\n","\n","# Subir directamente desde el buffer\n","s3.put_object(Bucket = bucket_name,\n","              Key    = s3_key,\n","              Body   = csv_buffer.getvalue()\n","              )\n","\n","print(f\"✅ Archivo subido a s3://{bucket_name}/{s3_key}\")\n"],"metadata":{"id":"TGE3sABd9NDM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fin = datetime.now()\n","print(\"Fin:\", fin.strftime(\"%Y-%m-%d %H:%M:%S\"))\n"],"metadata":{"id":"KcKdcnjS9P1z"},"execution_count":null,"outputs":[]}]}