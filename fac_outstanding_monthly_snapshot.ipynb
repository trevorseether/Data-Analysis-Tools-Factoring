{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### ACTUALIZAR MES EN EL fac_outstanding_monthly_snapshot\n",
        "EL MES COLOCADO ES EL ÚNICO QUE SE ACTUALIZA, DEJA IGUAL TODOS LOS DEMÁS"
      ],
      "metadata": {
        "id": "wfnYmsZD7otT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% corte actual\n",
        "mes_incorporar = '2025-09-30' # último día del mes, cambiar en cada ejecución"
      ],
      "metadata": {
        "id": "riu2Xj5B9VTu"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "inicio = datetime.now()\n",
        "print(\"Inicio:\", inicio.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "\n",
        "import pandas as pd\n",
        "!pip install boto3\n",
        "import boto3\n",
        "import json\n",
        "import io\n",
        "import os\n",
        "import numpy as np\n",
        "!pip install pyathena\n",
        "from pyathena import connect\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "hoy_formateado = datetime.today().strftime('%Y-%m-%d')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fwaeZR402F4",
        "outputId": "bccae795-9d9a-4f33-ca05-8a66aee8e707"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicio: 2025-10-18 20:08:43\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.12/dist-packages (1.40.55)\n",
            "Requirement already satisfied: botocore<1.41.0,>=1.40.55 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.40.55)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from boto3) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.55->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.55->boto3) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.55->boto3) (1.17.0)\n",
            "Requirement already satisfied: pyathena in /usr/local/lib/python3.12/dist-packages (3.19.0)\n",
            "Requirement already satisfied: boto3>=1.26.4 in /usr/local/lib/python3.12/dist-packages (from pyathena) (1.40.55)\n",
            "Requirement already satisfied: botocore>=1.29.4 in /usr/local/lib/python3.12/dist-packages (from pyathena) (1.40.55)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from pyathena) (2025.3.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from pyathena) (2.9.0.post0)\n",
            "Requirement already satisfied: tenacity>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from pyathena) (8.5.0)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3>=1.26.4->pyathena) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from boto3>=1.26.4->pyathena) (0.14.0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore>=1.29.4->pyathena) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->pyathena) (1.17.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_credenciales_athena = r\"credenciales actualizado.txt\" # no cambiar\n",
        "\n",
        "path = '/content/drive/MyDrive/BUSINESS ANALYTICS/FACTORING/PROYECTOS/fac_outstanding backups'"
      ],
      "metadata": {
        "id": "10Za2DzG3IKy"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% funciones de transformación de fechas\n",
        "mes_incorporar = pd.Timestamp(mes_incorporar)\n",
        "\n",
        "def eomonth(fecha):\n",
        "    \"\"\"\n",
        "    Devuelve el último día del mes de la fecha dada.\n",
        "    \"\"\"\n",
        "    fecha = pd.Timestamp(fecha)\n",
        "    return fecha + pd.offsets.MonthEnd(0)\n",
        "\n",
        "def prev_month_eomonth(fecha):\n",
        "    \"\"\"\n",
        "    Devuelve el último día del mes anterior a la fecha dada.\n",
        "    \"\"\"\n",
        "    fecha = pd.Timestamp(fecha)  # asegurar tipo Timestamp\n",
        "    fech2 = (fecha - pd.offsets.MonthBegin(1)) - pd.offsets.Day(1)\n",
        "    return pd.Timestamp(fech2)\n",
        "\n",
        "def convertir_codmes(fecha):\n",
        "    fecha = pd.Timestamp(mes_incorporar)\n",
        "    yyyymm = fecha.strftime(\"%Y%m\")\n",
        "    return yyyymm\n",
        "\n",
        "eo_mes_actual   = eomonth(mes_incorporar)\n",
        "eo_mes_anterior = prev_month_eomonth(mes_incorporar)\n",
        "codmes          = convertir_codmes(mes_incorporar)"
      ],
      "metadata": {
        "id": "kQ4ZAHij3Jmf"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%\n",
        "# Crea la carpeta si no existe\n",
        "os.chdir(path)\n",
        "\n",
        "folder_name = codmes\n",
        "os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "os.chdir(path + '/' + folder_name)"
      ],
      "metadata": {
        "id": "Rj4NdY9K3Nyx"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "QTYeMUwk5dDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac2b89bc-c4b0-4f14-cba9-7a0b6d4885f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(85377, 90)\n"
          ]
        }
      ],
      "source": [
        "#%% Credenciales de AmazonAthena\n",
        "with open('/content/' + txt_credenciales_athena) as f:\n",
        "    creds = json.load(f)\n",
        "\n",
        "conn = connect(\n",
        "    aws_access_key_id     = creds[\"AccessKeyId\"],\n",
        "    aws_secret_access_key = creds[\"SecretAccessKey\"],\n",
        "    aws_session_token     = creds[\"SessionToken\"],\n",
        "    s3_staging_dir        = creds[\"s3_staging_dir\"],\n",
        "    region_name           = creds[\"region_name\"]\n",
        "\n",
        "    )\n",
        "\n",
        "#%% lectura del corte anterior\n",
        "\n",
        "query = ''' select * from prod_datalake_master.\"ba__fac_outstanding_monthly_snapshot\"  '''\n",
        "\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(query)\n",
        "\n",
        "# Obtener los resultados\n",
        "resultados = cursor.fetchall()\n",
        "\n",
        "# Obtener los nombres de las columnas\n",
        "column_names = [desc[0] for desc in cursor.description]\n",
        "\n",
        "# Convertir los resultados a un DataFrame de pandas\n",
        "df_corte = pd.DataFrame(resultados, columns = column_names)\n",
        "\n",
        "df_corte.to_excel(f'extraido {hoy_formateado}.xlsx', index = False)\n",
        "\n",
        "del df_corte['_timestamp']\n",
        "\n",
        "print(df_corte.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% mes actual que vamos a incorporar\n",
        "\n",
        "query = ''' select * from prod_datalake_analytics.\"fac_outst_unidos_f_desembolso_jmontoya\"  '''\n",
        "\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(query)\n",
        "\n",
        "# Obtener los resultados\n",
        "resultados = cursor.fetchall()\n",
        "\n",
        "# Obtener los nombres de las columnas\n",
        "column_names = [desc[0] for desc in cursor.description]\n",
        "\n",
        "# Convertir los resultados a un DataFrame de pandas\n",
        "df_view = pd.DataFrame(resultados, columns = column_names)\n",
        "print(df_view.shape)\n",
        "\n",
        "df_view.to_excel(f'fac_outstanding_tiempo_real_{codmes} - {hoy_formateado}.xlsx',\n",
        "                  index = False)\n",
        "\n",
        "df_view_completo = df_view.copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnFesPnBzTgE",
        "outputId": "e549e5bb-5d7f-43b6-ffa1-97b04f285830"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(89864, 90)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% agregando el mes actual\n",
        "df_corte['codmes'] = df_corte['codmes'].astype(int)\n",
        "df_corte = df_corte[ df_corte['codmes'] < int(codmes) ] #fitrando el mes actual en caso de que quisieramos añadir datos nuevamente\n",
        "\n",
        "df_view['codmes'] = df_view['codmes'].astype(int)\n",
        "df_view  = df_view[ df_view['codmes'] == int(codmes)]\n",
        "\n",
        "#ASEGURANDO EL ORDENAMIENTO, PUES EXISTEN DIFERENCIAS POR MAYÚSCULAS Y MINÚSCULAS\n",
        "columnas = ['code', 'fecha_cierre', 'codmes', 'product_type', 'client_ruc', 'client_name', 'provider_ruc', 'provider_name', 'flag_newclient', 'flag_newprovider', 'transfer_date', 'ANTERIOR_TRANSFER', 'currency_request', 'currency_auctions', 'assigned_financing_rate', 'total_net_amount_pending_payment', 'e_payment_date_original', 'amount_financed', 'terms', 'amount_advance', 'advance_percentage', 'invoice_count', 'amount_of_invoices', 'assigned_name', 'assigned_last_name', 'company_id', 'user_third_party_id', 'client_id', 'provider_id', 'request_id', 'client_payment_id', 'payment_currency', 'payment_date', 'total_amount_paid', 'capital_paid', 'interest_paid', 'guarantee_paid', 'last_status', 'last_paid_date', 'facturas_vencimientos_iguales', 'fecha_confirmada_hubspot', 'max_payment_date_invoices', 'e_payment_date', 'cambio_fecha_vencimiento', 'q_desembolso', 'm_desembolso', 'new_clients', 'recurrent_clients', 'new_providers', 'recurrent_providers', 'remaining_capital', 'remaining_total_amount', 'actual_status', 'flag_excluir', 'dias_atraso', 'm_desembolso_soles', 'remaining_capital_soles', 'amount_financed_soles', 'exchange_rate', 'codmes_transfer', 'PAR1_m', 'PAR15_m', 'PAR30_m', 'PAR60_m', 'PAR90_m', 'PAR120_m', 'PAR180_m', 'PAR360_m', 'PAR1_q', 'PAR15_q', 'PAR30_q', 'PAR60_q', 'PAR90_q', 'PAR120_q', 'PAR180_q', 'PAR360_q', 'q_vigente', 'condoned', 'judicialized', 'rango_dias_atraso', 'rango_duracion', 'PAR1_ms', 'PAR15_ms', 'PAR30_ms', 'PAR60_ms', 'PAR90_ms', 'PAR120_ms', 'PAR180_ms', 'PAR360_ms', 'FLAG_ORIGEN_OPERACION']\n",
        "columnas_mayusc = [col.upper() for col in columnas]\n",
        "cc = df_corte.columns\n",
        "cc = [col.upper() for col in cc]\n",
        "cv = df_view.columns\n",
        "cv = [col.upper() for col in cv]\n",
        "\n",
        "df_corte.columns = cc\n",
        "df_corte = df_corte[columnas_mayusc]\n",
        "\n",
        "df_view.columns = cv\n",
        "df_view = df_view[columnas_mayusc]\n",
        "\n",
        "df_corte.columns = columnas\n",
        "df_view.columns  = columnas\n",
        "\n",
        "df_concatenado = pd.concat([df_corte, df_view], ignore_index=True)\n",
        "print(df_concatenado.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DidJkeAO7bAT",
        "outputId": "a8aaee49-c478-45cc-dee3-9f42df483043"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(85377, 90)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% CONVERTIR COLUMNAS DE FECHAS A UN SOLO FORMATO\n",
        "n_alertas = 0\n",
        "df_concatenado[\"fecha_cierre\"] = pd.to_datetime(df_concatenado[\"fecha_cierre\"],  format=\"mixed\")\n",
        "df_concatenado[\"fecha_cierre\"] = df_concatenado[\"fecha_cierre\"].dt.strftime(\"%Y-%m-%d\")\n",
        "alert = df_concatenado[ df_concatenado[\"fecha_cierre\"].isna() ]\n",
        "if alert.shape[0]>0:\n",
        "    print('alerta de nulos en fecha_cierre')\n",
        "    n_alertas += 1\n",
        "\n",
        "df_concatenado[\"transfer_date\"] = pd.to_datetime(df_concatenado[\"transfer_date\"],  format=\"mixed\")\n",
        "df_concatenado[\"transfer_date\"] = df_concatenado[\"transfer_date\"].dt.strftime(\"%Y-%m-%d\")\n",
        "alert = df_concatenado[ df_concatenado[\"transfer_date\"].isna() ]\n",
        "if alert.shape[0]>0:\n",
        "    print('alerta de nulos en transfer_date')\n",
        "    n_alertas += 1\n",
        "\n",
        "df_concatenado[\"e_payment_date_original\"] = pd.to_datetime(df_concatenado[\"e_payment_date_original\"],  format=\"mixed\")\n",
        "df_concatenado[\"e_payment_date_original\"] = df_concatenado[\"e_payment_date_original\"].dt.strftime(\"%Y-%m-%d\")\n",
        "alert = df_concatenado[ df_concatenado[\"e_payment_date_original\"].isna() ]\n",
        "if alert.shape[0]>0:\n",
        "    print('alerta de nulos en e_payment_date_original')\n",
        "    n_alertas += 1\n",
        "\n",
        "# df_concatenado[\"payment_date\"] = pd.to_datetime(df_concatenado[\"payment_date\"],  format=\"mixed\")\n",
        "# df_concatenado[\"payment_date\"] = df_concatenado[\"payment_date\"].dt.strftime(\"%Y-%m-%d\")\n",
        "# alert = df_concatenado[ df_concatenado[\"payment_date\"].isna() ]\n",
        "\n",
        "df_concatenado[\"e_payment_date\"] = pd.to_datetime(df_concatenado[\"e_payment_date\"],  format=\"mixed\")\n",
        "df_concatenado[\"e_payment_date\"] = df_concatenado[\"e_payment_date\"].dt.strftime(\"%Y-%m-%d\")\n",
        "alert = df_concatenado[ df_concatenado[\"e_payment_date\"].isna() ]\n",
        "if alert.shape[0]>0:\n",
        "    print('alerta de nulos en e_payment_date')\n",
        "    n_alertas += 1\n",
        "\n",
        "################################################################################\n",
        "class StopExecution(Exception):\n",
        "    pass\n",
        "if n_alertas >= 1:\n",
        "    raise StopExecution(\"Se canceló la ejecución por presencia de alertas\")\n",
        "else:\n",
        "    print(\"No se encontraron alertas\")\n",
        "################################################################################\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3XfMpCf7tg9",
        "outputId": "4df65244-c4ad-42c0-8102-ee69c87ebdcd"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No se encontraron alertas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% obtener ruc del corte más reciente, para unirlo por codigo de subasta, a aquellos casos donde falte ruc\n",
        "rucs = df_view_completo[['code', 'client_ruc', 'codmes']]\n",
        "rucs = rucs.sort_values(by = 'codmes', ascending = False)\n",
        "rucs = rucs.drop_duplicates(subset=['code'], keep=\"first\")\n",
        "rucs = rucs[ ~pd.isna(rucs['client_ruc']) ]\n",
        "del rucs['codmes']\n",
        "rucs.columns = ['code_aux', 'ruc_aux']\n",
        "\n",
        "df_concatenado = df_concatenado.merge(rucs,\n",
        "                                      left_on  = 'code',\n",
        "                                      right_on = 'code_aux',\n",
        "                                      how      = 'left')\n",
        "df_concatenado['client_ruc'] = np.where( ~df_concatenado['ruc_aux'].isnull(),\n",
        "                                         df_concatenado['ruc_aux'],\n",
        "                                         df_concatenado['client_ruc'] )\n",
        "del df_concatenado['code_aux']\n",
        "del df_concatenado['ruc_aux']"
      ],
      "metadata": {
        "id": "eErJ57BK783I"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% limpieza de texto del client_ruc y provider_ruc\n",
        "col_ruc = 'client_ruc'\n",
        "df_concatenado[col_ruc] = (\n",
        "    df_concatenado[col_ruc]\n",
        "    .astype(str)                 # convierte todo a string\n",
        "    .str.replace('.0','', regex=False)  # limpia floats mal guardados\n",
        "    .replace('None', pd.NA)      # convierte 'None' a valor nulo real\n",
        ")\n",
        "vr = df_concatenado[ (df_concatenado[col_ruc] == 'None') | (pd.isna(df_concatenado[col_ruc]))]\n",
        "\n",
        "col_ruc = 'provider_ruc'\n",
        "df_concatenado[col_ruc] = (\n",
        "    df_concatenado[col_ruc]\n",
        "    .astype(str)                 # convierte todo a string\n",
        "    .str.replace('.0','', regex=False)  # limpia floats mal guardados\n",
        "    .replace('None', pd.NA)      # convierte 'None' a valor nulo real\n",
        ")\n",
        "vr = df_concatenado[ (df_concatenado[col_ruc] == 'None') | (pd.isna(df_concatenado[col_ruc]))]"
      ],
      "metadata": {
        "id": "P3pUa53T9FTu"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% parchamiento del nombre del client_ruc\n",
        "clientes = df_concatenado[['client_ruc', 'client_name', 'codmes']]\n",
        "clientes = clientes.sort_values(by='codmes', ascending=False)\n",
        "clientes = clientes.drop_duplicates(subset=['client_ruc'], keep=\"first\")\n",
        "clientes = clientes[ ~pd.isna(clientes['client_ruc'])]\n",
        "clientes = clientes[ ~pd.isna(clientes['client_name'])]\n",
        "clientes.columns = ['client_ruc_aux', 'client_name_aux', 'codmes']\n",
        "\n",
        "df_concatenado = df_concatenado.merge(clientes[['client_ruc_aux', 'client_name_aux']],\n",
        "                                  left_on  = 'client_ruc',\n",
        "                                  right_on = 'client_ruc_aux',\n",
        "                                  how      = 'left')\n",
        "df_concatenado['client_name'] = np.where( ~df_concatenado['client_name_aux'].isnull(),\n",
        "                                         df_concatenado['client_name_aux'],\n",
        "                                         df_concatenado['client_name'])\n",
        "del df_concatenado['client_ruc_aux']\n",
        "del df_concatenado['client_name_aux']\n"
      ],
      "metadata": {
        "id": "Iq0ce1te9IlR"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Colocando el client y provider actual, de manera retroactiva, y modificando la enumeración de nuevo o recurrente\n",
        "\n",
        "df_concatenado = df_concatenado.sort_values(by = 'codmes', ascending = False)\n",
        "op_actual = df_concatenado[ df_concatenado['codmes'] == int(codmes) ]\n",
        "op_actual = op_actual[['code', 'client_ruc','client_name', 'provider_ruc', 'provider_name']]\n",
        "op_actual = op_actual.drop_duplicates(subset=['code'], keep=\"first\")\n",
        "op_actual.columns = ['code', 'client_ruc_aux','client_name_aux', 'provider_ruc_aux', 'provider_name_aux']\n",
        "\n",
        "df_concatenado = df_concatenado.merge(op_actual,\n",
        "                                      on = 'code',\n",
        "                                      how = 'left')\n",
        "df_concatenado['client_ruc'] = np.where( df_concatenado['client_ruc_aux'].notna(),\n",
        "                                         df_concatenado['client_ruc_aux'],\n",
        "                                         df_concatenado['client_ruc'])\n",
        "df_concatenado['client_name'] = np.where( df_concatenado['client_name_aux'].notna(),\n",
        "                                          df_concatenado['client_name_aux'],\n",
        "                                          df_concatenado['client_name'])\n",
        "df_concatenado['provider_ruc'] = np.where( df_concatenado['provider_ruc_aux'].notna(),\n",
        "                                           df_concatenado['provider_ruc_aux'],\n",
        "                                           df_concatenado['provider_ruc'])\n",
        "df_concatenado['provider_name'] = np.where( df_concatenado['provider_name_aux'].notna(),\n",
        "                                            df_concatenado['provider_name_aux'],\n",
        "                                            df_concatenado['provider_name'])\n",
        "del df_concatenado['client_ruc_aux']\n",
        "del df_concatenado['client_name_aux']\n",
        "del df_concatenado['provider_ruc_aux']\n",
        "del df_concatenado['provider_name_aux']"
      ],
      "metadata": {
        "id": "ludzSxSGRHwk"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Corrección de flag_newclient flag_newprovider, new_clients, recurrent_clients, new_providers, recurrent_providers\n",
        "df_concatenado['transfer_date_aux'] = pd.to_datetime(df_concatenado['transfer_date'])\n",
        "df_concatenado = df_concatenado.sort_values(by = ['codmes', 'transfer_date_aux'], ascending = [True,True])\n",
        "\n",
        "# Creamos el contador acumulado para cada cliente\n",
        "df_concatenado['flag_newclient'] = df_concatenado.groupby('client_ruc').cumcount() + 1\n",
        "df_concatenado['flag_newclient'] = df_concatenado['flag_newclient'].fillna(0).astype(int)\n",
        "df_concatenado['flag_newprovider'] = df_concatenado.groupby('provider_ruc').cumcount() + 1\n",
        "df_concatenado['flag_newprovider'] = df_concatenado['flag_newprovider'].fillna(0).astype(int)\n",
        "\n",
        "df_concatenado['new_clients'] = np.where(df_concatenado['flag_newclient'] == 1,\n",
        "                                         1,\n",
        "                                         0).astype(int)\n",
        "df_concatenado['recurrent_clients'] = np.where(df_concatenado['flag_newclient'] == 1,\n",
        "                                         0,\n",
        "                                         1).astype(int)\n",
        "df_concatenado['new_providers'] = np.where(df_concatenado['flag_newprovider'] == 1,\n",
        "                                         1,\n",
        "                                         0).astype(int)\n",
        "df_concatenado['recurrent_providers'] = np.where(df_concatenado['flag_newprovider'] == 1,\n",
        "                                         0,\n",
        "                                         1).astype(int)\n",
        "\n",
        "del df_concatenado['transfer_date_aux']\n",
        "\n"
      ],
      "metadata": {
        "id": "ITKeQ8F3bybg"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%\n",
        "\n",
        "# Cliente de S3\n",
        "s3 = boto3.client(\n",
        "    \"s3\",\n",
        "    aws_access_key_id       = creds[\"AccessKeyId\"],\n",
        "    aws_secret_access_key   = creds[\"SecretAccessKey\"],\n",
        "    aws_session_token       = creds[\"SessionToken\"],\n",
        "    region_name             = creds[\"region_name\"]\n",
        ")\n",
        "\n",
        "# ==== CONFIGURACIÓN ====\n",
        "bucket_name = \"prod-datalake-raw-730335218320\"\n",
        "s3_prefix = \"manual/ba/fac_outstanding_monthly_snapshot/\" # carpeta lógica en el bucket\n",
        "\n",
        "# ==== EXPORTAR A PARQUET EN MEMORIA ====\n",
        "csv_buffer = io.StringIO()\n",
        "df_concatenado.to_csv(csv_buffer, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "# Nombre de archivo con timestamp (opcional, para histórico)\n",
        "s3_key = f\"{s3_prefix}fac_outstanding_monthly_snapshot.csv\"\n",
        "\n",
        "# Subir directamente desde el buffer\n",
        "s3.put_object(Bucket = bucket_name,\n",
        "              Key    = s3_key,\n",
        "              Body   = csv_buffer.getvalue()\n",
        "              )\n",
        "\n",
        "print(f\"✅ Archivo subido a s3://{bucket_name}/{s3_key}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGE3sABd9NDM",
        "outputId": "1fbcbc5d-ebfc-4f47-d474-d5a04be25c0b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Archivo subido a s3://prod-datalake-raw-730335218320/manual/ba/fac_outstanding_monthly_snapshot/fac_outstanding_monthly_snapshot.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fin = datetime.now()\n",
        "print(\"Fin:\", fin.strftime(\"%Y-%m-%d %H:%M:%S\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcKdcnjS9P1z",
        "outputId": "000c8dae-d559-4dfa-8c4f-9d8c555fbca5"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fin: 2025-10-18 20:18:25\n"
          ]
        }
      ]
    }
  ]
}